<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Quinn McGaugh and Otis Milliken AI WEBSITE</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Middlebury Relationship <br/> Predictor</h1>
        <p>AI Final Project by Otis Milliken and Quin McGaugh</p>
        <p>Using Decision Trees with Random Forrest to Predict Relationship Status</p>
        <p class="view"><a href="https://github.com/quinmcg/FinalProjectAI">View the Project on GitHub </a></p>
        <p><em>View the <a href="https://docs.google.com/document/d/1tBR2TCfxEjODB6rnanns1hJPE4ViXXdfLoWQg86Gmlk/edit">project proposal</a>.</em></p>
      </header>
      <section>
        <h1>Try Out Our Project</h1>
        <p> We'd love for you to try out our project! To do so, please follow the steps below. Feel free to email us if you run into any issues </p>
        <ol>
          <li>
            <p> To try out the project clone the <a href="https://docs.google.com/document/d/1tBR2TCfxEjODB6rnanns1hJPE4ViXXdfLoWQg86Gmlk/edit">repository</a> </p>
          </li>
          <li>
            <p>Some libraries are required to run this project. Please run the following commands in your terminal</p>
            <pre><code>pip install sklearn <br/>pip install graphviz <br/>pip install numpy <br/>pip install pandas <br/>pip install matplotlib <br/>pip install tabulate</code></pre>
          </li>
          <li>
            <p>The project can be run by python3 main.py whilst in the project folder. For a list of configurable options (including forrest size, method, and test data) run<p>
            <pre><code>python3 main.py -h </code></pre>
          </p>
        </ol> 

       

        <h2>Reasoning behind project</h2>

        <p>While searching for a project topic, our group decided we wanted to walk away with something applicable to our average Middlebury student, but have some kind of impact beyond this project. We decided upon using a dataset created by former Sociology Professor Peggy Nelson for her research methods class up until 2020.</p>

        <p>The dataset contains 987 responses which although is small compared to other dataset, it is quite large compared to the Middlebury student population of 2580. The dataset itself is a survey of Middlebury students that asks a variety of social questions from relationship status to GPA. </p>
        <p>In addition to the data we got from the past survey, we also collected 60 responses as well from the current year that we could test our trees against as well.

        <p>Our goal was to create a fun algorithm that can predict the relationship status of Middlebury Students based on their response to a series of non-academic, social questions about preferences and beliefs at Middlebury.</p>

        <h2>Basic overview of how our code works</h2>

        <p>Our code is split into 3 parts: the main class, the Decision tree class, and the Random Forrest class. <br/>
        The Decision Tree class can build a tree, render a tree, and classify an observation based on a created tree</p>

        <ul>
          <li>
          <p> This is our Decision Tree Class Methods</p>
            <pre><code>class DecisionTree:<br/> <br/>def __init__(self, features, classification, method, id)<br/>def buildTree(self) <br/>def renderTree(self)<br/>def classifyTree(self, observation)
            </code></pre>
          </li>
          <li>
          <p> This is our Random Forest Class Methods </p>
            <pre><code>class RandomForest: </br><br/>def __init__(self, numtrees, trainingfeat, trainingclass, method)<br/>def buildForest(self)<br/>def classfiyObservation(self, observation, method)<br/>def testAccuracy(self, testingfeat, testingclass)
            </code></pre>
          </li>
          <li>
            <p>Our main class is called when program is executed. It parses the arguments passed by the user through command line and trains the model</p>
          </li>
        </ul> 

        <h2>Random Forest Algorithm Explained</h2>
          <p>Random Forests are way to obtain greater accuracy with decision trees. In essence, it works by simulate a ton of decision trees and return the majority classification of the testing data among them. Each decision tree is trained on random data entries with replacement from the training set and with a random set of features. The idea is to have enough trees so that outlying data and features don't have too much of an influence on classification. There is some randomness in random forests so it might not classify data in the same way each time.<br/>We also use two different methods to create our decision trees: Gini and Entropy. </p>
          <p> Gini Index is calculated: 1 - &#931 p^2 </p>
          <p> Entropy is calculated:  - &#931 p * log(p) </p>
          <p> It depends on the data set on which one works better. Entropy since it uses logs can take slightly longer </p>

        <h2>Algorithm performance</h2>
          <table>
            <tbody>
          <tr>
            <th>Method</th>
            <th>Number of Trees in Forest</th>
            <th>RunTime</th>
            <th>Accuracy</th>
          </tr>
          <tr>
            <td>Gini</td>
            <td>300</td>
            <td>Alot?</td>
            <td>Alot?</td>
          </tr>
          </tbody>
          </table>

        <h2>Example Tree Renderings </h2>
        <img src="treerender2.pdf" alt="tree render">
        <img src="4.pdf" alt="tree render">

        <h2>Bugs and difficulties</h2>

         <dl>
          <dt>Getting used to python</dt>
          <dd>One of our initial difficulties was getting used to python and the python libraries that we had to use. These included python with sci-learn, numpy, pandas, graphviz, and matplotlib.</dd>
          <dt>Preprocessing Data</dt>
          <dd>Our data was not immediately usable so we had to figure out a way to make it into the right format</dd>
          <dt>Figuring out how sklearn and pandas</dt>
          <dd>We had some trouble halfway through the project with the way that sklearn and pandas handled data. Specifically, pandas worked with dataframes which are slightly different than other data structures that we are used to </dd>
        </dl>

      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/Hokalaka2/AIFinalWebsite">Otis Milliken and Quin McGaugh</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
